% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/td_query.R
\name{spark_execute_td_presto}
\alias{spark_execute_td_presto}
\title{Read Treasure Data data from Presto via api-presto gateway}
\usage{
spark_execute_td_presto(sc, source, query, options = list())
}
\arguments{
\item{sc}{A \code{spark_connection}.}

\item{source}{Data base name of the table on TD. Example: \samp{"sample_datasets"}}

\item{query}{A SQL to execute}

\item{options}{A list of strings with additional options.}
}
\description{
Read Treasure Data data from Presto via api-presto gateway
}
\details{
You can execute queries to TD through td-spark. You have to set \code{spark.td.apikey},
\code{spark.serializer} appropreately.
}
\examples{
\dontrun{
library(dplyr)
config <- spark_config()

config$spark.td.apikey <- Sys.getenv("TD_API_KEY")
config$spark.serializer <- "org.apache.spark.serializer.KryoSerializer"
config$spark.sql.execution.arrow.enabled <- "true"

sc <- spark_connect(master = "local", config = config)

spark_execute_td_presto(sc,
  "sample_datasets",
  "create table if not exists orders (key bigint, status varchar, price double)")
}

}
\seealso{
Other Spark serialization routines: \code{\link{spark_read_td_presto}},
  \code{\link{spark_read_td_query}},
  \code{\link{spark_read_td}}, \code{\link{spark_write_td}}
}
\concept{Spark serialization routines}
